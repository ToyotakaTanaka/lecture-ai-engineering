# Gemma 2 チャットボットアプリケーション

このアプリケーションは、Streamlitを使用したLLM（大規模言語モデル）ベースのチャットボットで、ユーザーからの質問に回答し、その回答に対するフィードバックを収集・分析する機能を提供します。

## アプリケーションの概要

このチャットボットアプリケーションは、以下の主要な機能を提供しています：

1. **チャット機能**：Gemmaモデルを使用して、ユーザーの質問に対する回答を生成します
2. **フィードバック機能**：生成された回答に対するフィードバックを収集し、データベースに保存します
3. **履歴閲覧**：過去のチャット履歴とフィードバックを閲覧できます
4. **評価指標分析**：回答の正確性、応答時間、BLEUスコアなどの評価指標を分析・可視化します
5. **サンプルデータ管理**：テスト用のサンプルデータを追加・削除できます

## システム構成

このアプリケーションは、以下のモジュールで構成されています：

- **`app.py`**: アプリケーションのエントリーポイント。チャット機能、履歴閲覧、サンプルデータ管理のUIを提供します。
- **`ui.py`**: チャットページや履歴閲覧ページなど、アプリケーションのUIロジックを管理します。
- **`llm.py`**: LLMモデルのロードとテキスト生成を行うモジュール。
- **`database.py`**: SQLiteデータベースを使用してチャット履歴やフィードバックを保存・管理します。
- **`metrics.py`**: BLEUスコアやコサイン類似度など、回答の評価指標を計算するモジュール。
- **`data.py`**: サンプルデータの作成やデータベースの初期化を行うモジュール。
- **`config.py`**: アプリケーションの設定（モデル名やデータベースファイル名）を管理します。
- **`requirements.txt`**: このアプリケーションを実行するために必要なPythonパッケージ。

## セットアップと実行方法

### 必要な依存関係のインストール

```bash
cd day1/02_streamlit_app
pip install -r requirements.txt
```

### Hugging Faceの認証設定

このアプリケーションは、Hugging Faceからモデルをダウンロードするために認証が必要です。Streamlitのシークレット機能を使用して認証情報を設定します。

1. `.streamlit`ディレクトリを作成します
2. `secrets.toml`ファイルを作成し、以下の内容を追加します

```toml
[huggingface]
token = "あなたのHugging Faceトークン"
```

### アプリケーションの実行

```bash
streamlit run app.py
```

### Google Colabでの実行

このアプリケーションはGoogle Colabでも実行できます。`day1_practice.ipynb`ノートブックを開き、関連するセルを実行してください。Colabでは、GPUを有効にすることで、より高速な推論が可能になります。

## 主要な機能

### 1. チャット機能

チャットページでは、ユーザーが質問を入力し、LLMモデルから回答を得ることができます。

- テキストエリアに質問を入力
- 「質問を送信」ボタンをクリック
- モデルが回答を生成
- 回答に対してフィードバックを提供

### 2. フィードバック機能

回答に対して以下のフィードバックを提供できます：

- **正確性評価**：「正確」「部分的に正確」「不正確」の3段階で評価
- **正確な回答**：より正確な回答がある場合に入力
- **コメント**：自由形式のコメント

### 3. 履歴閲覧

履歴閲覧ページでは、過去のチャット履歴とフィードバックを閲覧できます。

- フィルタリング機能：正確性に基づいて履歴をフィルタリング
- ページネーション：複数ページにわたる履歴の閲覧
- 詳細表示：各チャットの詳細情報と評価指標の表示

### 4. 評価指標分析

評価指標分析ページでは、回答の品質に関する様々な指標を分析・可視化できます。

- **正確性の分布**：正確、部分的に正確、不正確の分布を表示
- **応答時間と他の指標の関係**：応答時間とBLEUスコアなどの関係を散布図で表示
- **評価指標の統計**：各指標の統計情報を表示
- **正確性レベル別の平均スコア**：正確性レベル別の各指標の平均値を表示
- **効率性スコア**：正確性と応答時間から計算される効率性スコアを表示

### 5. サンプルデータ管理

サンプルデータ管理ページでは、テスト用のサンプルデータを追加・削除できます。

- サンプルデータの追加：事前定義されたサンプルデータをデータベースに追加
- データベースのクリア：データベース内のすべてのレコードを削除
- 評価指標の説明：各評価指標の詳細な説明を表示

## 評価指標

このアプリケーションでは、以下の評価指標を使用して回答の品質を評価します：

- **正確性スコア (is_correct)**：回答の正確さを3段階で評価（1.0: 正確、0.5: 部分的に正確、0.0: 不正確）
- **応答時間 (response_time)**：質問を投げてから回答を得るまでの時間（秒）
- **BLEU スコア (bleu_score)**：機械翻訳評価指標で、正解と回答のn-gramの一致度を測定（0〜1の値）
- **類似度スコア (similarity_score)**：TF-IDFベクトルのコサイン類似度による、正解と回答の意味的な類似性（0〜1の値）
- **単語数 (word_count)**：回答に含まれる単語の数
- **関連性スコア (relevance_score)**：正解と回答の共通単語の割合（0〜1の値）
- **効率性スコア (efficiency_score)**：正確性を応答時間で割った値

## 技術スタック

- **Streamlit**: インタラクティブなWebアプリケーションを構築するためのフレームワーク
- **Transformers**: Hugging Faceが提供するLLMモデルのロードと推論を行うライブラリ
- **SQLite**: チャット履歴やフィードバックを保存するための軽量データベース
- **NLTK & Janome**: 自然言語処理と日本語形態素解析のためのライブラリ
- **scikit-learn**: 機械学習と評価指標計算のためのライブラリ
- **pandas**: データ操作と分析のためのライブラリ
- **pyngrok**: ローカルサーバーをインターネットに公開するためのツール

## 注意事項

- このアプリケーションは、`config.py`で指定されたモデル（デフォルト: google/gemma-2-2b-jpn-it）を使用します。
- GPUを使用することで、より高速な推論が可能になります。
- 初回起動時には、モデルのダウンロードに時間がかかる場合があります。
- データベースファイル（`chat_feedback.db`）は、アプリケーションと同じディレクトリに作成されます。
